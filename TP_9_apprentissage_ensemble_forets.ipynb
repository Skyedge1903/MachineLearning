{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMPY\n",
    "import numpy as np\n",
    "\n",
    "# STATS\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm, skew\n",
    "\n",
    "# MATPLOTLIB\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# plt.style.use('fivethirtyeight') \n",
    "\n",
    "# PANDAS\n",
    "import pandas as pd \n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None) \n",
    "\n",
    "# SEABRON\n",
    "import seaborn as sns\n",
    "\n",
    "# SCIKIT-LEARN: PRE-PROCESSING\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder # encodage des variables catégorielles ordinales\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder # encodage des variables catégorielles nominales\n",
    "from sklearn.preprocessing import StandardScaler # standardisation des variables numériques\n",
    "from sklearn.preprocessing import MinMaxScaler # normalisation des variables numériques\n",
    "from sklearn.preprocessing import RobustScaler # normalisation des variables numériques\n",
    "from sklearn.impute import SimpleImputer # imputation des valeurs manquantes\n",
    "from sklearn.impute import KNNImputer # imputation des valeurs manquantes par la méthode KNN\n",
    "from sklearn.feature_selection  import SelectKBest # sélectionner \n",
    "from sklearn. preprocessing import PolynomialFeatures \n",
    "\n",
    "# MODELES PREDICTIFS\n",
    "\n",
    "## REGRESSION\n",
    "from sklearn.linear_model import LogisticRegression # régréssion logistique\n",
    "\n",
    "## SVM \n",
    "from sklearn.svm import LinearSVC # machines à vecteurs de support (linéaire)\n",
    "from sklearn.svm import SVC # machines à vecteurs de support (non-linéaire)\n",
    "\n",
    "## SGD\n",
    "from sklearn.linear_model import SGDClassifier #  classifieurs (SVM, régression logistique, etc.) avec un algorithme SGD\n",
    "\n",
    "## ARBRES, FORETS, APRRENTISSAGE D'ENSEMBLE\n",
    "from sklearn.tree import DecisionTreeClassifier # arbres classification\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "\n",
    "## KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier # KPP voisins\n",
    "\n",
    "# VALIDATION CROISEE + OPTIMISATION\n",
    "from sklearn.model_selection import train_test_split # séparation des données en train et test set\n",
    "from sklearn.model_selection import cross_val_score # validation croisée pour comparaison entre modèles\n",
    "from sklearn.model_selection import validation_curve # courbe de validation: visulaisr les scores lors du choix d'un hyperparamétre\n",
    "from sklearn.model_selection import GridSearchCV # tester plusieurs hyperparamètres\n",
    "from sklearn.model_selection import RandomizedSearchCV # tester arbitrairement plusieurs hyperparamètres\n",
    "from sklearn.model_selection import learning_curve # courbe d'apprentissage: visualisation les scores du train et du validation sets en fonction des quanitiés des données\n",
    " \n",
    "## EVALUATION: METRIQUES DE CLASSIFICATION\n",
    "from sklearn.metrics import accuracy_score # exactitude (accuracy)\n",
    "from sklearn.metrics import f1_score # F1-score\n",
    "from sklearn.metrics import confusion_matrix # matrice de confusion\n",
    "from sklearn.metrics import plot_confusion_matrix # graphique de la matrice de confusion\n",
    "from sklearn.metrics import classification_report # rapport pour le modèle de classification\n",
    "\n",
    "## EVALUATION: COURBE ROC\n",
    "from sklearn.metrics import auc # aire sous la courbe \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve \n",
    "from sklearn.metrics import precision_recall_curve #\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "\n",
    "# PIPELINE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# TRANSFORMATEUR COMPOSITE (PRE-PROCESSOR + MODELE)\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "\n",
    "# WARNINGS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_covid = pd.read_excel('../data/covid-19.xlsx', engine='openpyxl')\n",
    "df = data_covid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nettoyage générale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rate = (df.isna().sum() / df.shape[0])\n",
    "# missing_rate.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_tests_viraux = list(df.columns[(missing_rate < 0.80) & (missing_rate >0.75)])\n",
    "cols_taux_sanguins = list(df.columns[(missing_rate < 0.9) & (missing_rate >0.88)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_age_cible = ['Patient age quantile', 'SARS-Cov-2 exam result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter notre dataframe\n",
    "df = df[cols_age_cible + cols_taux_sanguins + cols_tests_viraux] # ['a'] + ['b'] = ['a', 'b']\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Démarches de travail  pour tester différentes idées du pre-processing: TrainTest - Nettoyage - Encodage (Test 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train set , Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.shape, testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset['SARS-Cov-2 exam result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset['SARS-Cov-2 exam result'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes('object'):\n",
    "    print(f'{col :-<50} {df[col].unique()}') # créer un sytème de marge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'positive': 1,\n",
    "       'negative': 0,\n",
    "       'detected': 1,\n",
    "       'not_detected': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes('object'):\n",
    "    df[col] = df[col].map(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts() # pas de variables de type object dans notre dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction encodage \n",
    "def encodage(df): # on peut passer soit le trainset ou le testset\n",
    "    code = {'positive': 1,\n",
    "       'negative': 0,\n",
    "       'detected': 1,\n",
    "       'not_detected': 0}\n",
    "    for col in df.select_dtypes('object'):\n",
    "        df[col] = df[col].map(code)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction nettoyage\n",
    "def nettoyage(df):\n",
    "    return df.dropna(axis=0) # le plus simple possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focntion preprocessing\n",
    "def preprocessing(df):\n",
    "    df = encodage(df)\n",
    "    df = nettoyage(df)\n",
    "    X = df.drop('SARS-Cov-2 exam result', axis=1)\n",
    "    y = df['SARS-Cov-2 exam result']\n",
    "    print(y.value_counts())\n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocessing(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = preprocessing(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation - Évaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeModel = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    N, train_score, val_score = learning_curve(model, \n",
    "                                              X_train, \n",
    "                                              y_train, \n",
    "                                              cv=5, \n",
    "                                              scoring='f1',\n",
    "                                              train_sizes=np.linspace(0.1, 1, 10))\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(N, train_score.mean(axis=1), label='train_score')\n",
    "    plt.plot(N, val_score.mean(axis=1), label='validation score')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(treeModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeModel.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(treeModel.feature_importances_, index=X_train.columns).plot.bar(figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrainTest - Nettoyage - Encodage (Test 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[cols_age_cible + cols_taux_sanguins]# + cols_tests_viraux] # ['a'] + ['b'] = ['a', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset1, testset1 = train_test_split(df1, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, y_train1 = preprocessing(trainset1)\n",
    "X_test1, y_test1 = preprocessing(testset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation1(model):\n",
    "    model.fit(X_train1, y_train1)\n",
    "    y_pred = model.predict(X_test1)\n",
    "    print(confusion_matrix(y_test1, y_pred))\n",
    "    print(classification_report(y_test1, y_pred))\n",
    "    \n",
    "    N, train_score, val_score = learning_curve(model, \n",
    "                                              X_train1, \n",
    "                                              y_train1, \n",
    "                                              cv=5, \n",
    "                                              scoring='f1',\n",
    "                                              train_sizes=np.linspace(0.1, 1, 10))\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(N, train_score.mean(axis=1), label='train_score')\n",
    "    plt.plot(N, val_score.mean(axis=1), label='validation score')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(treeModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdforestModel = RandomForestClassifier(random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(rdforestModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdforestModel.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on va injecter ce tableau dans un dataframe\n",
    "pd.DataFrame(rdforestModel.feature_importances_, index=X_train.columns).plot.bar(figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df['etre_malde'] = df[cols_tests_viraux].sum(axis=1) >= 1 # patient a au moins une maladie\n",
    "    df = df.drop(cols_tests_viraux, axis=1)\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    df = encodage(df)\n",
    "    df = feature_engineering(df)\n",
    "    df = nettoyage(df)\n",
    "    X = df.drop('SARS-Cov-2 exam result', axis=1)\n",
    "    y = df['SARS-Cov-2 exam result']\n",
    "    print(y.value_counts())\n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocessing(trainset)\n",
    "X_test, y_test = preprocessing(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(rdforestModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rdforestModel.feature_importances_, index=X_train.columns).plot.bar(figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on va faire un pipleline \n",
    "from sklearn.feature_selection  import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(SelectKBest(f_classif, k=10), \n",
    "                     RandomForestClassifier(random_state=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(SelectKBest(f_classif, k=5), \n",
    "                     RandomForestClassifier(random_state=0))\n",
    "evaluation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(PolynomialFeatures(2), SelectKBest(f_classif, k=10),\n",
    "                     RandomForestClassifier(random_state=0))\n",
    "evaluation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_pipeline(PolynomialFeatures(2, include_bias=False), SelectKBest(f_classif, k=10))\n",
    "\n",
    "# on laisse les modèles sur leurs hyperpramètres de base\n",
    "RandomForest = make_pipeline(preprocessor, RandomForestClassifier(random_state=0))\n",
    "AdaBoost = make_pipeline(preprocessor, AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), random_state=0))\n",
    "SVM = make_pipeline(preprocessor, StandardScaler(), SVC(random_state=0))\n",
    "KNN = make_pipeline(preprocessor, StandardScaler(), KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models = {'RandomForest':RandomForest,\n",
    "                  'AdaBoost':AdaBoost,\n",
    "                  'SVM':SVM,\n",
    "                  'KNN':KNN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name, model in list_of_models.items():\n",
    "    print('*' *90)\n",
    "    print(name)\n",
    "    print('*' *90)\n",
    "    evaluation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {'svc__gamma':[1e-3, 1e-4], \n",
    "                'svc__C':[1, 10, 100, 1000]} # attention ne mettre pas d'espace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(SVM, hyper_params, scoring='recall', cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {'svc__gamma':[1e-3, 1e-4], \n",
    "                'svc__C':[1, 10, 100, 1000],\n",
    "                'pipeline__polynomialfeatures__degree':[2, 3],\n",
    "                'pipeline__selectkbest__k':range(50, 70)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = RandomizedSearchCV(SVM, hyper_params, scoring='recall', cv=5, n_iter=50)\n",
    "random_grid.fit(X_train, y_train)\n",
    "print(random_grid.best_params_)\n",
    "y_pred = random_grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred)) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(random_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Courbe Précision / Recalll \n",
    "# seuil de la frontière de décision pour notre modèle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = \\\n",
    "precision_recall_curve(y_test, random_grid.best_estimator_.decision_function(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(threshold, precision[:-1], label='precision')\n",
    "plt.plot(threshold, recall[:-1], label='recall')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_final(model, X, threshold=0):\n",
    "    return model.decision_function(X) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_final(random_grid.best_estimator_, X_test, threshold=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid.best_estimator_.decision_function(X_test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation Adaboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    # algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
    "    \n",
    "# AdaBoostClassifier(base_estimator=None,\n",
    "#                     n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)[source]¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {'adaboostclassifier__n_estimators':[60, 100], \n",
    "                'adaboostclassifier__learning_rate':[1e-1, 1]} # attention ne mettre pas d'espace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(AdaBoost, hyper_params, scoring='recall', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred)) # l'ordre est tres important sinon tous les calculs sont inversés\n",
    "# dans la matrice de confusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = { \n",
    "                'adaboostclassifier__base_estimator__max_depth':[1,2],\n",
    "                'adaboostclassifier__n_estimators':[1, 2, 3, 4, 5], \n",
    "                'adaboostclassifier__learning_rate':[2],\n",
    "                'pipeline__polynomialfeatures__degree':[2, 3],\n",
    "                'pipeline__selectkbest__k':range(50, 60)} # attention ne mettre pas d'espace  # 50, 70\n",
    "# si on fait çà avec gridsearch cv on est mort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_grid = RandomizedSearchCV(AdaBoost, hyper_params, scoring='recall', cv=5, n_iter=50)\n",
    "random_grid.fit(X_train, y_train)\n",
    "print(random_grid.best_params_)\n",
    "y_pred = random_grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred)) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(random_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

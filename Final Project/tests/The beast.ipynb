{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction des défauts de paiement des cartes de crédit\n",
    "\n",
    "### Tutoriel pour les débutants en analyse de classification à l'aide de scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005.\n",
    "\n",
    "\n",
    "# Table of Content\n",
    "\n",
    "* [Objectives](#obj)\n",
    "* [Importing packages and loading data](#imp)\n",
    "* [Feature Engineering](#fe)\n",
    "* [Exploratory Data Analysis (EDA)](#eda)\n",
    "    * [Mapping the target: categorizing](#map)\n",
    "    * [Descriptive Statistics](#stat)\n",
    "    * [Standardizing and plotting features](#std)\n",
    "    * [Correlation](#corr)\n",
    "* [Machine Learning: Classification models](#ml)\n",
    "    * [Feature Selection](#fs)\n",
    "    * [Spliting the data: train and test](#sp)\n",
    "    * [Logistic Regression (original data)](#lr1)\n",
    "    * [Logistic Regression (standardized features)](#lr2)\n",
    "    * [Logistic Regression (most important features)](#lr3)\n",
    "    * [ExtraTree-decision](#tree)\n",
    "    * [Random-Forest Classifier](#rf)\n",
    "* [Comparison of model performance](#sum)\n",
    "    * [Receiver operating characteristic (ROC) Curve](#roc)\n",
    "    * [Mean Accuracy (coss-validation)](#ac)\n",
    "    * [Precision, Recall, F1-score](#m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='obj'></a>\n",
    "## Objectives:<br>\n",
    "-       Identify the key drivers that determine the likelihood of credit card default.\n",
    "-       Predict the likelihood of credit card default for customers of the Bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imp'></a>\n",
    "## Importing packages and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# here we will import the libraries used for machine learning\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy.stats import randint\n",
    "import pandas as pd # data processing, CSV file I/O, data manipulation \n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "from pandas import set_option\n",
    "plt.style.use('ggplot') # nice plots\n",
    "\n",
    "from sklearn.model_selection import train_test_split # to split the data into two parts\n",
    "from sklearn.linear_model import LogisticRegression # to apply the Logistic regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold # for cross validation\n",
    "from sklearn.model_selection import GridSearchCV # for tuning parameter\n",
    "from sklearn.model_selection import RandomizedSearchCV  # Randomized search on hyper parameters.\n",
    "from sklearn.preprocessing import StandardScaler # for normalization\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics # for the check the error and accuracy of the model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X1: LIMIT_BAL</th>\n",
       "      <th>X2: SEX</th>\n",
       "      <th>X3: EDUCATION</th>\n",
       "      <th>X4: MARRIAGE</th>\n",
       "      <th>X5: AGE</th>\n",
       "      <th>X6: PAY_1</th>\n",
       "      <th>X7: PAY_2</th>\n",
       "      <th>X8: PAY_3</th>\n",
       "      <th>X9: PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>X15: BILL_AMT4</th>\n",
       "      <th>X16: BILL_AMT5</th>\n",
       "      <th>X17: BILL_AMT6</th>\n",
       "      <th>X18: PAY_AMT1</th>\n",
       "      <th>X19: PAY_AMT2</th>\n",
       "      <th>X20: PAY_AMT3</th>\n",
       "      <th>X21: PAY_AMT4</th>\n",
       "      <th>X22: PAY_AMT5</th>\n",
       "      <th>X23: PAY_AMT6</th>\n",
       "      <th>Y: default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18078</th>\n",
       "      <td>18079</td>\n",
       "      <td>450000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>208005</td>\n",
       "      <td>194608</td>\n",
       "      <td>201044</td>\n",
       "      <td>20255</td>\n",
       "      <td>50171</td>\n",
       "      <td>7096</td>\n",
       "      <td>6604</td>\n",
       "      <td>10012</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>5190</td>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29121</td>\n",
       "      <td>29368</td>\n",
       "      <td>13174</td>\n",
       "      <td>1598</td>\n",
       "      <td>1599</td>\n",
       "      <td>928</td>\n",
       "      <td>600</td>\n",
       "      <td>627</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14259</th>\n",
       "      <td>14260</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>3797</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>3797</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26052</th>\n",
       "      <td>26053</td>\n",
       "      <td>140000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>123208</td>\n",
       "      <td>97154</td>\n",
       "      <td>97687</td>\n",
       "      <td>4729</td>\n",
       "      <td>5434</td>\n",
       "      <td>4751</td>\n",
       "      <td>3500</td>\n",
       "      <td>3500</td>\n",
       "      <td>3800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12293</th>\n",
       "      <td>12294</td>\n",
       "      <td>230000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>58171</td>\n",
       "      <td>56033</td>\n",
       "      <td>47192</td>\n",
       "      <td>29525</td>\n",
       "      <td>50014</td>\n",
       "      <td>8242</td>\n",
       "      <td>7032</td>\n",
       "      <td>5030</td>\n",
       "      <td>8007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  X1: LIMIT_BAL  X2: SEX  X3: EDUCATION  X4: MARRIAGE  X5: AGE  \\\n",
       "18078  18079         450000        1              1             2       34   \n",
       "5189    5190          30000        1              2             2       24   \n",
       "14259  14260          30000        2              3             2       51   \n",
       "26052  26053         140000        2              2             2       38   \n",
       "12293  12294         230000        2              2             2       35   \n",
       "\n",
       "       X6: PAY_1  X7: PAY_2  X8: PAY_3  X9: PAY_4  ...  X15: BILL_AMT4  \\\n",
       "18078          0          0          0          0  ...          208005   \n",
       "5189           0          0          0          0  ...           29121   \n",
       "14259         -1         -1         -1         -1  ...            3797   \n",
       "26052          0          0          0          0  ...          123208   \n",
       "12293         -1         -1          0          0  ...           58171   \n",
       "\n",
       "       X16: BILL_AMT5  X17: BILL_AMT6  X18: PAY_AMT1  X19: PAY_AMT2  \\\n",
       "18078          194608          201044          20255          50171   \n",
       "5189            29368           13174           1598           1599   \n",
       "14259               0               0              0            400   \n",
       "26052           97154           97687           4729           5434   \n",
       "12293           56033           47192          29525          50014   \n",
       "\n",
       "       X20: PAY_AMT3  X21: PAY_AMT4  X22: PAY_AMT5  X23: PAY_AMT6  \\\n",
       "18078           7096           6604          10012          10000   \n",
       "5189             928            600            627           1500   \n",
       "14259           3797              0              0              0   \n",
       "26052           4751           3500           3500           3800   \n",
       "12293           8242           7032           5030           8007   \n",
       "\n",
       "       Y: default payment next month  \n",
       "18078                              0  \n",
       "5189                               0  \n",
       "14259                              0  \n",
       "26052                              0  \n",
       "12293                              0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('credit.xls')\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are variables that need to be converted to categories:\n",
    "* __SEX:__ Gender   \n",
    "                    1 = male \n",
    "                    2 = female\n",
    "* __EDUCATION:__     \n",
    "                     1 = graduate school \n",
    "                     2 = university \n",
    "                     3 = high school \n",
    "                     4 = others \n",
    "                     5 = unknown \n",
    "                     6 = unknown\n",
    "* __MARRIAGE:__ Marital status \n",
    "                    1 = married\n",
    "                    2 = single\n",
    "                    3 = others\n",
    "* __PAY_0,2,3,4,5,6:__ Repayment status in September 2005, August 2005, July 2005, June 2005, May 2005, April 2005 (respectivey)\n",
    "                    -2= no consumption\n",
    "                    -1= pay duly\n",
    "                    1 = payment delay for one month\n",
    "                    2 = payment delay for two months\n",
    "                    ... \n",
    "                    8 = payment delay for eight months\n",
    "                    9 = payment delay for nine months and above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fe'></a>\n",
    "## Feature engineering\n",
    "\n",
    "The data has been already encoded and cleaned. However, some categorical data have repeated categories. For instance, the variable ‘education’ has three categories with similar information:<br>\n",
    "4: others, 5: unknown, and 6: unknown<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                         Non-Null Count  Dtype\n",
      "---  ------                         --------------  -----\n",
      " 0   X1: LIMIT_BAL                  30000 non-null  int64\n",
      " 1   X2: SEX                        30000 non-null  int64\n",
      " 2   X3: EDUCATION                  30000 non-null  int64\n",
      " 3   X4: MARRIAGE                   30000 non-null  int64\n",
      " 4   X5: AGE                        30000 non-null  int64\n",
      " 5   X6: PAY_1                      30000 non-null  int64\n",
      " 6   X7: PAY_2                      30000 non-null  int64\n",
      " 7   X8: PAY_3                      30000 non-null  int64\n",
      " 8   X9: PAY_4                      30000 non-null  int64\n",
      " 9   X10: PAY_5                     30000 non-null  int64\n",
      " 10  X11: PAY_6                     30000 non-null  int64\n",
      " 11  X12: BILL_AMT1                 30000 non-null  int64\n",
      " 12  X13: BILL_AMT2                 30000 non-null  int64\n",
      " 13  X14: BILL_AMT3                 30000 non-null  int64\n",
      " 14  X15: BILL_AMT4                 30000 non-null  int64\n",
      " 15  X16: BILL_AMT5                 30000 non-null  int64\n",
      " 16  X17: BILL_AMT6                 30000 non-null  int64\n",
      " 17  X18: PAY_AMT1                  30000 non-null  int64\n",
      " 18  X19: PAY_AMT2                  30000 non-null  int64\n",
      " 19  X20: PAY_AMT3                  30000 non-null  int64\n",
      " 20  X21: PAY_AMT4                  30000 non-null  int64\n",
      " 21  X22: PAY_AMT5                  30000 non-null  int64\n",
      " 22  X23: PAY_AMT6                  30000 non-null  int64\n",
      " 23  Y: default payment next month  30000 non-null  int64\n",
      "dtypes: int64(24)\n",
      "memory usage: 5.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.rename(columns={\"default.payment.next.month\": \"Default\"}, inplace=True)\n",
    "data.drop('ID', axis = 1, inplace =True) # drop column \"ID\"\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Default'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8de3ba0137de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Separating features and target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDefault\u001b[0m     \u001b[1;31m# target default=1 or non-default=0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Default'"
     ]
    }
   ],
   "source": [
    "# Separating features and target\n",
    "y = data.Default     # target default=1 or non-default=0\n",
    "features = data.drop('Default', axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'EDUCATION'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'EDUCATION'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ccba8ebaa65e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EDUCATION'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'EDUCATION'"
     ]
    }
   ],
   "source": [
    "data['EDUCATION'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categories 4:others, 5:unknown, and 6:unknown can be grouped into a single class '4'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'EDUCATION'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'EDUCATION'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7e11b5dc2184>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EDUCATION'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EDUCATION'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EDUCATION'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EDUCATION'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EDUCATION'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EDUCATION'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EDUCATION'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EDUCATION'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EDUCATION'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'EDUCATION'"
     ]
    }
   ],
   "source": [
    "data['EDUCATION']=np.where(data['EDUCATION'] == 5, 4, data['EDUCATION'])\n",
    "data['EDUCATION']=np.where(data['EDUCATION'] == 6, 4, data['EDUCATION'])\n",
    "data['EDUCATION']=np.where(data['EDUCATION'] == 0, 4, data['EDUCATION'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After grouping, the education column has the following categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'EDUCATION'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'EDUCATION'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ccba8ebaa65e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EDUCATION'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'EDUCATION'"
     ]
    }
   ],
   "source": [
    "data['EDUCATION'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the column 'marriage' should have three categories: 1 = married, 2 = single, 3 = others but it contains a category '0' which will be joined to the category '3'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MARRIAGE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'MARRIAGE'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9eb21ab493ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MARRIAGE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'MARRIAGE'"
     ]
    }
   ],
   "source": [
    "data['MARRIAGE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MARRIAGE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'MARRIAGE'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e5a1e1f9a3a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MARRIAGE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MARRIAGE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MARRIAGE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MARRIAGE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'MARRIAGE'"
     ]
    }
   ],
   "source": [
    "data['MARRIAGE']=np.where(data['MARRIAGE'] == 0, 3, data['MARRIAGE'])\n",
    "data['MARRIAGE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "<a id='map'></a>\n",
    "### Mapping the target: categorizing\n",
    "\n",
    "From this sample of 30,000 credit card holders, there were 6,636 default credit cards; that is, the proportion of default in the data is 22,1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Default'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-51154dec41ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# The frequency of defaults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0myes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDefault\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mno\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0myes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Percentage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Default'"
     ]
    }
   ],
   "source": [
    "# The frequency of defaults\n",
    "yes = data.Default.sum()\n",
    "no = len(data)-yes\n",
    "B\n",
    "# Percentage\n",
    "yes_perc = round(yes/len(data)*100, 1)\n",
    "no_perc = round(no/len(data)*100, 1)\n",
    "\n",
    "import sys \n",
    "plt.figure(figsize=(7,4))\n",
    "sns.set_context('notebook', font_scale=1.2)\n",
    "sns.countplot('Default',data=data, palette=\"Blues\")\n",
    "plt.annotate('Non-default: {}'.format(no), xy=(-0.3, 15000), xytext=(-0.3, 3000), size=12)\n",
    "plt.annotate('Default: {}'.format(yes), xy=(0.7, 15000), xytext=(0.7, 3000), size=12)\n",
    "plt.annotate(str(no_perc)+\" %\", xy=(-0.3, 15000), xytext=(-0.1, 8000), size=12)\n",
    "plt.annotate(str(yes_perc)+\" %\", xy=(0.7, 15000), xytext=(0.9, 8000), size=12)\n",
    "plt.title('COUNT OF CREDIT CARDS', size=14)\n",
    "#Removing the frame\n",
    "plt.box(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='stat'></a>\n",
    "### Descriptive Statistics\n",
    "The table below shows the descriptive statistics of the variables of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY STATISTICS OF NUMERIC COLUMNS\n",
      "\n",
      "                                 count       mean        std       min       25%       50%  \\\n",
      "X1: LIMIT_BAL                  30000.0  167484.32  129747.66   10000.0  50000.00  140000.0   \n",
      "X2: SEX                        30000.0       1.60       0.49       1.0      1.00       2.0   \n",
      "X3: EDUCATION                  30000.0       1.85       0.79       0.0      1.00       2.0   \n",
      "X4: MARRIAGE                   30000.0       1.55       0.52       0.0      1.00       2.0   \n",
      "X5: AGE                        30000.0      35.49       9.22      21.0     28.00      34.0   \n",
      "X6: PAY_1                      30000.0      -0.02       1.12      -2.0     -1.00       0.0   \n",
      "X7: PAY_2                      30000.0      -0.13       1.20      -2.0     -1.00       0.0   \n",
      "X8: PAY_3                      30000.0      -0.17       1.20      -2.0     -1.00       0.0   \n",
      "X9: PAY_4                      30000.0      -0.22       1.17      -2.0     -1.00       0.0   \n",
      "X10: PAY_5                     30000.0      -0.27       1.13      -2.0     -1.00       0.0   \n",
      "X11: PAY_6                     30000.0      -0.29       1.15      -2.0     -1.00       0.0   \n",
      "X12: BILL_AMT1                 30000.0   51223.33   73635.86 -165580.0   3558.75   22381.5   \n",
      "X13: BILL_AMT2                 30000.0   49179.08   71173.77  -69777.0   2984.75   21200.0   \n",
      "X14: BILL_AMT3                 30000.0   47013.15   69349.39 -157264.0   2666.25   20088.5   \n",
      "X15: BILL_AMT4                 30000.0   43262.95   64332.86 -170000.0   2326.75   19052.0   \n",
      "X16: BILL_AMT5                 30000.0   40311.40   60797.16  -81334.0   1763.00   18104.5   \n",
      "X17: BILL_AMT6                 30000.0   38871.76   59554.11 -339603.0   1256.00   17071.0   \n",
      "X18: PAY_AMT1                  30000.0    5663.58   16563.28       0.0   1000.00    2100.0   \n",
      "X19: PAY_AMT2                  30000.0    5921.16   23040.87       0.0    833.00    2009.0   \n",
      "X20: PAY_AMT3                  30000.0    5225.68   17606.96       0.0    390.00    1800.0   \n",
      "X21: PAY_AMT4                  30000.0    4826.08   15666.16       0.0    296.00    1500.0   \n",
      "X22: PAY_AMT5                  30000.0    4799.39   15278.31       0.0    252.50    1500.0   \n",
      "X23: PAY_AMT6                  30000.0    5215.50   17777.47       0.0    117.75    1500.0   \n",
      "Y: default payment next month  30000.0       0.22       0.42       0.0      0.00       0.0   \n",
      "\n",
      "                                     75%       max  \n",
      "X1: LIMIT_BAL                  240000.00  1.00e+06  \n",
      "X2: SEX                             2.00  2.00e+00  \n",
      "X3: EDUCATION                       2.00  6.00e+00  \n",
      "X4: MARRIAGE                        2.00  3.00e+00  \n",
      "X5: AGE                            41.00  7.90e+01  \n",
      "X6: PAY_1                           0.00  8.00e+00  \n",
      "X7: PAY_2                           0.00  8.00e+00  \n",
      "X8: PAY_3                           0.00  8.00e+00  \n",
      "X9: PAY_4                           0.00  8.00e+00  \n",
      "X10: PAY_5                          0.00  8.00e+00  \n",
      "X11: PAY_6                          0.00  8.00e+00  \n",
      "X12: BILL_AMT1                  67091.00  9.65e+05  \n",
      "X13: BILL_AMT2                  64006.25  9.84e+05  \n",
      "X14: BILL_AMT3                  60164.75  1.66e+06  \n",
      "X15: BILL_AMT4                  54506.00  8.92e+05  \n",
      "X16: BILL_AMT5                  50190.50  9.27e+05  \n",
      "X17: BILL_AMT6                  49198.25  9.62e+05  \n",
      "X18: PAY_AMT1                    5006.00  8.74e+05  \n",
      "X19: PAY_AMT2                    5000.00  1.68e+06  \n",
      "X20: PAY_AMT3                    4505.00  8.96e+05  \n",
      "X21: PAY_AMT4                    4013.25  6.21e+05  \n",
      "X22: PAY_AMT5                    4031.50  4.27e+05  \n",
      "X23: PAY_AMT6                    4000.00  5.29e+05  \n",
      "Y: default payment next month       0.00  1.00e+00  \n"
     ]
    }
   ],
   "source": [
    "set_option('display.width', 100)\n",
    "set_option('precision', 2)\n",
    "\n",
    "print(\"SUMMARY STATISTICS OF NUMERIC COLUMNS\")\n",
    "print()\n",
    "print(data.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average value for the amount of credit card limit is 167,484 NT dollars. The standard deviation is 129,747 NT dollars, ranging from 10,000 to 1M NT dollars.<br>\n",
    "Education level is mostly graduate school (1) and university (2). Most of the clients are either marrined or single (less frequent the other status). Average age is 35.5 years, with a standard deviation of 9.2 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of explanatory variables by defaulted and non-defaulted cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe with categorical variables\n",
    "subset = data[['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', \n",
    "               'PAY_5', 'PAY_6', 'Default']]\n",
    "\n",
    "f, axes = plt.subplots(3, 3, figsize=(20, 15), facecolor='white')\n",
    "f.suptitle('FREQUENCY OF CATEGORICAL VARIABLES (BY TARGET)')\n",
    "ax1 = sns.countplot(x=\"SEX\", hue=\"Default\", data=subset, palette=\"Blues\", ax=axes[0,0])\n",
    "ax2 = sns.countplot(x=\"EDUCATION\", hue=\"Default\", data=subset, palette=\"Blues\",ax=axes[0,1])\n",
    "ax3 = sns.countplot(x=\"MARRIAGE\", hue=\"Default\", data=subset, palette=\"Blues\",ax=axes[0,2])\n",
    "ax4 = sns.countplot(x=\"PAY_0\", hue=\"Default\", data=subset, palette=\"Blues\", ax=axes[1,0])\n",
    "ax5 = sns.countplot(x=\"PAY_2\", hue=\"Default\", data=subset, palette=\"Blues\", ax=axes[1,1])\n",
    "ax6 = sns.countplot(x=\"PAY_3\", hue=\"Default\", data=subset, palette=\"Blues\", ax=axes[1,2])\n",
    "ax7 = sns.countplot(x=\"PAY_4\", hue=\"Default\", data=subset, palette=\"Blues\", ax=axes[2,0])\n",
    "ax8 = sns.countplot(x=\"PAY_5\", hue=\"Default\", data=subset, palette=\"Blues\", ax=axes[2,1])\n",
    "ax9 = sns.countplot(x=\"PAY_6\", hue=\"Default\", data=subset, palette=\"Blues\", ax=axes[2,2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = list(data[data['Default'] == 1]['LIMIT_BAL'])\n",
    "x2 = list(data[data['Default'] == 0]['LIMIT_BAL'])\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.set_context('notebook', font_scale=1.2)\n",
    "#sns.set_color_codes(\"pastel\")\n",
    "plt.hist([x1, x2], bins = 40, normed=False, color=['steelblue', 'lightblue'])\n",
    "plt.xlim([0,600000])\n",
    "plt.legend(['Yes', 'No'], title = 'Default', loc='upper right', facecolor='white')\n",
    "plt.xlabel('Limit Balance (NT dollar)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('LIMIT BALANCE HISTOGRAM BY TYPE OF CREDIT CARD', SIZE=15)\n",
    "plt.box(False)\n",
    "plt.savefig('ImageName', format='png', dpi=200, transparent=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 30,000 credit card clients.\n",
    "\n",
    "The average value for the amount of credit card limit is 167,484 NT dollars. The standard deviation is 129,747 NT dollars, ranging from 10,000 to 1M NT dollars.\n",
    "\n",
    "Education level is mostly graduate school and university.\n",
    "\n",
    "Most of the clients are either marrined or single (less frequent the other status).\n",
    "\n",
    "Average age is 35.5 years, with a standard deviation of 9.2.\n",
    "\n",
    "As the value 0 for default payment means 'not default' and value 1 means 'default', the mean of 0.221 means that there are 22.1% of credit card contracts that will default next month (will verify this in the next sections of this analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Repayment = data[['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']]\n",
    "\n",
    "Repayment = pd.concat([y,Repayment],axis=1)\n",
    "Repayment = pd.melt(Repayment,id_vars=\"Default\",\n",
    "                    var_name=\"Repayment_Status\",\n",
    "                    value_name='value')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.set_context('notebook', font_scale=1.2)\n",
    "sns.boxplot(y=\"value\", x=\"Repayment_Status\", hue=\"Default\", data=Repayment, palette='Blues')\n",
    "plt.legend(loc='best', title= 'Default', facecolor='white')\n",
    "plt.xlim([-1.5,5.5])\n",
    "plt.title('REPAYMENT STATUS - BOXPLOT', size=14)\n",
    "plt.box(False)\n",
    "plt.savefig('ImageName', format='png', dpi=200);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that PAY_0 (Repayment status in September) and PAY_2 (Repayment status in August)  have more discriminatory power the repayment status in other months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='std'></a>\n",
    "### Standardizing and plotting the data\n",
    "The boxplot below reveals that features are in different scales and units. Many models use some form of distance when making predictions, and therefore, it is recommended to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data are distributed in a wide range (below), need to be normalizded.\n",
    "plt.figure(figsize=(15,3))\n",
    "ax= data.drop('Default', axis=1).boxplot(data.columns.name, rot=90)\n",
    "outliers = dict(markerfacecolor='b', marker='p')\n",
    "ax= features.boxplot(features.columns.name, rot=90, flierprops=outliers)\n",
    "plt.xticks(size=12)\n",
    "ax.set_ylim([-5000,100000])\n",
    "plt.box(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization of data was performed; i.e, all features are centered around zero and have variance one. Features were plotted again, using a violin plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdX = (features - features.mean()) / (features.std())              # standardization\n",
    "data_st = pd.concat([y,stdX.iloc[:,:]],axis=1)\n",
    "data_st = pd.melt(data_st,id_vars=\"Default\",\n",
    "                    var_name=\"features\",\n",
    "                    value_name='value')\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.set_context('notebook', font_scale=1)\n",
    "sns.violinplot(y=\"value\", x=\"features\", hue=\"Default\", data=data_st,split=True, \n",
    "               inner=\"quart\", palette='Blues')\n",
    "plt.legend(loc=4, title= 'Default', facecolor='white')\n",
    "plt.ylim([-3,3])\n",
    "plt.title('STANDARDIZED FEATURES - VIOLIN PLOT', size=14)\n",
    "plt.box(False)\n",
    "plt.savefig('ImageName', format='png', dpi=200, transparent=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='corr'></a>\n",
    "### Correlation\n",
    "A correlation matrix of all variables is shown in the heatmap below. The only feature with a notable positive correlation with the dependent variable ‘Default’ is re-payment status during the last month (September). The highest negative correlation with default occurs with Limit_Balance, indicating that customers with lower limit balance are more likely to default. It can also be observed that some variables are highly correlated to each other, that is the case of the amount of bill statement and the repayment status in different months.\n",
    "\n",
    "Looking at correlations matrix, defined via Pearson function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  looking at correlations matrix, defined via Pearson function  \n",
    "corr = data.corr() # .corr is used to find corelation\n",
    "f,ax = plt.subplots(figsize=(8, 7))\n",
    "sns.heatmap(corr, cbar = True,  square = True, annot = False, fmt= '.1f', \n",
    "            xticklabels= True, yticklabels= True\n",
    "            ,cmap=\"coolwarm\", linewidths=.5, ax=ax)\n",
    "plt.title('CORRELATION MATRIX - HEATMAP', size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmat shows that features are correlated with each other (collinearity), such us like PAY_0,2,3,4,5,6 and BILL_AMT1,2,3,4,5,6. In those cases, the correlation is positive.\n",
    "\n",
    "Uncorrelated data are poentially more useful: discriminatory!\n",
    "\n",
    "**What do correlations mean?**<br>\n",
    "\n",
    "Lets separately fit correlated and uncorrelated data via linear regression: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='LIMIT_BAL', y= 'BILL_AMT2', data = data, hue ='Default', \n",
    "           palette='coolwarm')\n",
    "plt.title('Linear Regression: distinguishing between Default and Non-default', size=16)\n",
    "\n",
    "\n",
    "sns.lmplot(x='BILL_AMT1', y= 'BILL_AMT2', data = data, hue ='Default', \n",
    "           palette='coolwarm')\n",
    "plt.title('Linear Regression: Cannot distinguish between Default and Non-default', size=16);\n",
    "\n",
    "print('Uncorrelated data are poentially more useful: discrimentory!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ml'></a>\n",
    "## Machine Learning: Classification models\n",
    "\n",
    "The classification models used for this analysis are: Logistic Regression, Decision Tree and Random Forest Classifier.<br>\n",
    "\n",
    "To build machine learning models the original data was divided into features (X) and target (y) and then split into train (80%) and test (20%) sets. Thus, the algorithms would be trained on one set of data and tested out on a completely different set of data (not seen before by the algorithm).\n",
    "\n",
    "<a id='sp'></a>\n",
    "### Spliting the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset\n",
    "X = data.drop('Default', axis=1)  \n",
    "y = data['Default']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with standardized features\n",
    "Xstd_train, Xstd_test, ystd_train, ystd_test = train_test_split(stdX,y, test_size=0.2, stratify=y,\n",
    "                                                                random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fs'></a>\n",
    "### Feature Selection\n",
    "\n",
    "#### Recursive Feature Elimination\n",
    "Recursive Feature Elimination (RFE) is based on the idea to repeatedly construct a model and choose either the best or worst performing feature, setting the feature aside and then repeating the process with the rest of the features. This process is applied until all features in the dataset are exhausted. The goal of RFE is to select features by recursively considering smaller and smaller sets of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 3\n",
    "model = LogisticRegression()\n",
    "rfe_stand = RFE(model, NUM_FEATURES)\n",
    "fit_stand = rfe_stand.fit(stdX, y)\n",
    "#print(\"St Model Num Features:\", fit_stand.n_features_)\n",
    "#print(\"St Model Selected Features:\", fit_stand.support_)\n",
    "print(\"Std Model Feature Ranking:\", fit_stand.ranking_)\n",
    "# calculate the score for the selected features\n",
    "score_stand = rfe_stand.score(stdX,y)\n",
    "print(\"Standardized Model Score with selected features is: %f (%f)\" % (score_stand.mean(), score_stand.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(features.columns)\n",
    "print('Most important features (RFE): %s'% feature_names[rfe_stand.support_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Repayment status in September (PAY_0)\n",
    "* Amount of bill statement in September (BILL_AMT1)\n",
    "* Amount of previous payments in August (PAY_AMT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with three most important features\n",
    "Ximp = stdX[['PAY_0', 'BILL_AMT1', 'PAY_AMT2']]\n",
    "X_tr, X_t, y_tr, y_t = train_test_split(Ximp,y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lr1'></a>\n",
    "### Logistic Regression (original data)\n",
    "\n",
    "Logistic Regression is one of the simplest algorithms which estimates the relationship between one dependent binary variable and independent variables, computing the probability of occurrence of an event. The regulation parameter C controls the trade-off between increasing complexity (overfitting) and keeping the model simple (underfitting). For large values of C, the power of regulation is reduced and the model increases its complexity, thus overfitting the data.<br>\n",
    "\n",
    "The parameter ‘C’ was tuned using RandomizedSearchCV( ) for the different datasets: original, standardized and with most important features. Once the parameter ‘C’ was defined for each dataset, the logistic regression model initiated and then fitted to the training data, as it was described in the methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the hyperparameter grid, (not scaled data)\n",
    "param_grid = {'C': np.logspace(-5, 8, 15)}\n",
    "\n",
    "# Instantiate a logistic regression classifier\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "logreg_cv = RandomizedSearchCV(logreg,param_grid , cv=5, random_state=0)\n",
    "\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C=0.00005, random_state=0)\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "print('Accuracy:', metrics.accuracy_score(y_pred,y_test))\n",
    "\n",
    "## 5-fold cross-validation \n",
    "cv_scores =cross_val_score(LR, X, y, cv=5)\n",
    "\n",
    "# Print the 5-fold cross-validation scores\n",
    "print()\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "print(\"Average 5-Fold CV Score: {}\".format(round(np.mean(cv_scores),4)),\n",
    "      \", Standard deviation: {}\".format(round(np.std(cv_scores),4)))\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "ConfMatrix = confusion_matrix(y_test,LR.predict(X_test))\n",
    "sns.heatmap(ConfMatrix,annot=True, cmap=\"Blues\", fmt=\"d\", \n",
    "            xticklabels = ['Non-default', 'Default'], \n",
    "            yticklabels = ['Non-default', 'Default'])\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has not power predicting default credit cards. However, it can be observed that the average accuracy of the model is about 78%, which demonstrates that this metrics is not appropriate for the evaluation of this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lr2'></a>\n",
    "### Logistic Regression (standardized features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the RandomizedSearchCV object:\n",
    "logreg_cv_std = RandomizedSearchCV(logreg,param_grid , cv=5, random_state=0)\n",
    "\n",
    "# Fit it to the standardized data\n",
    "logreg_cv_std.fit(Xstd_train, ystd_train)\n",
    "\n",
    "# Print the tuned parameters \n",
    "print(\"Tuned Logistic Regression Parameters with standardized features: {}\".format(logreg_cv_std.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRS = LogisticRegression(C=3.73, random_state=0)\n",
    "LRS.fit(Xstd_train, ystd_train)\n",
    "y_pred = LRS.predict(Xstd_test)\n",
    "print('Accuracy:', metrics.accuracy_score(y_pred,ystd_test))\n",
    "\n",
    "## 5-fold cross-validation \n",
    "cv_scores =cross_val_score(LRS, stdX, y, cv=5)\n",
    "\n",
    "# Print the 5-fold cross-validation scores\n",
    "print()\n",
    "print(classification_report(ystd_test, y_pred))\n",
    "print()\n",
    "print(\"Average 5-Fold CV Score: {}\".format(round(np.mean(cv_scores),4)),\n",
    "      \", Standard deviation: {}\".format(round(np.std(cv_scores),4)))\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "ConfMatrix = confusion_matrix(ystd_test,LRS.predict(Xstd_test))\n",
    "sns.heatmap(ConfMatrix,annot=True, cmap=\"Blues\", fmt=\"d\", \n",
    "            xticklabels = ['Non-default', 'Default'], \n",
    "            yticklabels = ['Non-default', 'Default'])\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title(\"Confusion Matrix - Logistic Regression with standardized data\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the logistic regression model standardized data improved compared to the model built with the original dataset. By using the standardized dataset, the model is able to predict defaults; however, with a very low recall (0.24)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lr3'></a>\n",
    "### Logistic Regression (most important features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_imp = LogisticRegression(C=3.73, random_state=0)\n",
    "LR_imp.fit(X_tr, y_tr)\n",
    "y_pred = LR_imp.predict(X_t)\n",
    "print('Accuracy:', metrics.accuracy_score(y_pred,y_t))\n",
    "\n",
    "## 5-fold cross-validation \n",
    "cv_scores =cross_val_score(LR_imp, Ximp, y, cv=5)\n",
    "\n",
    "# Print the 5-fold cross-validation scores\n",
    "print()\n",
    "print(classification_report(y_t, y_pred))\n",
    "print()\n",
    "print(\"Average 5-Fold CV Score: {}\".format(round(np.mean(cv_scores),4)),\n",
    "      \", Standard deviation: {}\".format(round(np.std(cv_scores),4)))\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "ConfMatrix = confusion_matrix(y_t,LR_imp.predict(X_t))\n",
    "sns.heatmap(ConfMatrix,annot=True, cmap=\"Blues\", fmt=\"d\", \n",
    "            xticklabels = ['Non-default', 'Default'], \n",
    "            yticklabels = ['Non-default', 'Default'])\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title(\"Confusion Matrix - Logistic Regression (most important features)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using just important features for building the model, there is a slight improvement in performance with respect to the previous model. Therefore, taking into account three features only, the model has the same predictive power than using 24 features. Thus, future strategies should be focused on: repayment status in September (PAY_0), amount of bill statement in September (BILL_AMT1), and amount of previous payments in August (PAY_AMT2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tree'></a>\n",
    "### Decision Tree Classifier\n",
    "Decision Tree is another very popular algorithm for classification problems because it is easy to interpret and understand. An internal node represents a feature, the branch represents a decision rule, and each leaf node represents the outcome. Some advantages of decision trees are that they require less data preprocessing, i.e., no need to normalize features. However, noisy data can be easily overfitted and results in biased results when the data set is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [1,2,3,4,5,6,7,8,9],\n",
    "              \"max_features\": [1,2,3,4,5,6,7,8,9],\n",
    "              \"min_samples_leaf\": [1,2,3,4,5,6,7,8,9],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_distributions=param_dist, cv=5, random_state=0)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree = DecisionTreeClassifier(criterion= 'gini', max_depth= 7, \n",
    "                                     max_features= 9, min_samples_leaf= 2, \n",
    "                                     random_state=0)\n",
    "Tree.fit(X_train, y_train)\n",
    "y_pred = Tree.predict(X_test)\n",
    "print('Accuracy:', metrics.accuracy_score(y_pred,y_test))\n",
    "\n",
    "## 5-fold cross-validation \n",
    "cv_scores =cross_val_score(Tree, X, y, cv=5)\n",
    "\n",
    "# Print the 5-fold cross-validation scores\n",
    "print()\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "print(\"Average 5-Fold CV Score: {}\".format(round(np.mean(cv_scores),4)), \n",
    "      \", Standard deviation: {}\".format(round(np.std(cv_scores),4)))\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "ConfMatrix = confusion_matrix(y_test,Tree.predict(X_test))\n",
    "sns.heatmap(ConfMatrix,annot=True, cmap=\"Blues\", fmt=\"d\", \n",
    "            xticklabels = ['Non-default', 'Default'], \n",
    "            yticklabels = ['Non-default', 'Default'])\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title(\"Confusion Matrix - Decision Tree\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the decision tree model improved compared to the logistic regression model showed previously. However, the recall is still low (0.33)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rf'></a>\n",
    "### Random Forest Classifier\n",
    "Random forest classifier is comprised of multiple decision trees. It creates different random subset of decision trees from the training set as its predictors and selects the best solution by means of voting. As a result, the Random Forest model avoids overfitting problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "param_dist = {'n_estimators': [50,100,150,200,250],\n",
    "               \"max_features\": [1,2,3,4,5,6,7,8,9],\n",
    "               'max_depth': [1,2,3,4,5,6,7,8,9],\n",
    "               \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_cv = RandomizedSearchCV(rf, param_distributions = param_dist, \n",
    "                           cv = 5, random_state=0, n_jobs = -1)\n",
    "\n",
    "rf_cv.fit(X, y)\n",
    "\n",
    "print(\"Tuned Random Forest Parameters: %s\" % (rf_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ran = RandomForestClassifier(criterion= 'gini', max_depth= 6, \n",
    "                                     max_features= 5, n_estimators= 150, \n",
    "                                     random_state=0)\n",
    "Ran.fit(X_train, y_train)\n",
    "y_pred = Ran.predict(X_test)\n",
    "print('Accuracy:', metrics.accuracy_score(y_pred,y_test))\n",
    "\n",
    "## 5-fold cross-validation \n",
    "cv_scores =cross_val_score(Ran, X, y, cv=5)\n",
    "\n",
    "# Print the 5-fold cross-validation scores\n",
    "print()\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "print(\"Average 5-Fold CV Score: {}\".format(round(np.mean(cv_scores),4)),\n",
    "      \", Standard deviation: {}\".format(round(np.std(cv_scores),4)))\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "ConfMatrix = confusion_matrix(y_test,Ran.predict(X_test))\n",
    "sns.heatmap(ConfMatrix,annot=True, cmap=\"Blues\", fmt=\"d\", \n",
    "            xticklabels = ['Non-default', 'Default'], \n",
    "            yticklabels = ['Non-default', 'Default'])\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title(\"Confusion Matrix - Random Forest\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sum'></a>\n",
    "## Comparison of model performance\n",
    "The metrics used to evaluate performance of the different models: accuracy, precision, recall, f1-score, AUC (ROC), and confusion matrix were employed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='roc'></a>\n",
    "### Receiver operating characteristic (ROC) Curve\n",
    "Receiver Operating Characteristic (ROC) curve is a plot of the true positive rate against the false positive rate. The AUC is the Area Under Curve. If the AUC is high, the model is better distinguishing between positive and negative class. The ROC curve is plotted with “True Positive Rate” or Recall (on the y-axis) against the “False Positive Rate” (on the x-axis). When the AUC is 0.5 means that the model has no discrimination capacity to distinguish between positive and negative class.\n",
    "\n",
    "The Receiver operating characteristic (ROC) Curve with the respective area under the curve (AUC) are shown below for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_RF = Ran.predict_proba(X_test)[::,1]\n",
    "fpr1, tpr1, _ = metrics.roc_curve(y_test,  y_pred_proba_RF)\n",
    "auc1 = metrics.roc_auc_score(y_test, y_pred_proba_RF)\n",
    "\n",
    "y_pred_proba_DT = Tree.predict_proba(X_test)[::,1]\n",
    "fpr2, tpr2, _ = metrics.roc_curve(y_test,  y_pred_proba_DT)\n",
    "auc2 = metrics.roc_auc_score(y_test, y_pred_proba_DT)\n",
    "\n",
    "y_pred_proba_LR = LR.predict_proba(X_test)[::,1]\n",
    "fpr3, tpr3, _ = metrics.roc_curve(y_test,  y_pred_proba_LR)\n",
    "auc3 = metrics.roc_auc_score(y_test, y_pred_proba_LR)\n",
    "\n",
    "y_pred_proba_LRS = LRS.predict_proba(Xstd_test)[::,1]\n",
    "fpr4, tpr4, _ = metrics.roc_curve(ystd_test,  y_pred_proba_LRS)\n",
    "auc4 = metrics.roc_auc_score(ystd_test, y_pred_proba_LRS)\n",
    "\n",
    "y_pred_proba_LRimp = LR_imp.predict_proba(X_t)[::,1]\n",
    "fpr5, tpr5, _ = metrics.roc_curve(y_t,  y_pred_proba_LRimp)\n",
    "auc5 = metrics.roc_auc_score(y_t, y_pred_proba_LRimp)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr1,tpr1,label=\"Random Forest, auc=\"+str(round(auc1,2)))\n",
    "plt.plot(fpr2,tpr2,label=\"Decision Tree, auc=\"+str(round(auc2,2)))\n",
    "plt.plot(fpr3,tpr3,label=\"LogReg, auc=\"+str(round(auc3,2)))\n",
    "plt.plot(fpr4,tpr4,label=\"LogReg(std), auc=\"+str(round(auc4,2)))\n",
    "plt.plot(fpr5,tpr5,label=\"LogReg(Std&Imp), auc=\"+str(round(auc5,2)))\n",
    "plt.legend(loc=4, title='Models', facecolor='white')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC', size=15)\n",
    "plt.box(False)\n",
    "plt.savefig('ImageName', format='png', dpi=200, transparent=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest AUC is obtained for the Random Forest Classifier model, with a value of 0.77. This means there is 77% chance that the model will be able to distinguish between default class and non-default class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ac'></a>\n",
    "### Mean Accuracy (coss-validation)\n",
    "Accuracy is the ratio of correctly predicted observation to the overall observations and it is one of the most intuitive measurements of performance. However, a high accuracy rate does not always mean we have a perfect model. In fact, it only works well when the datasets are symmetric. It can be misleading when classes are imbalanced.\n",
    "\n",
    "Using K-fold cross-validation it is possible to obtain less biased models and avoid overfitting the data. In this case it was used a 5-fold cross-validation, as shown in the code below.\n",
    "\n",
    "cv_scores = cross_val_score(Model, X, y, cv=5)\n",
    "\n",
    "After cross-validation there are five values of accuracy, so it was calculated the mean and standard deviation of all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append different models\n",
    "models = []\n",
    "\n",
    "# Logistic Regression\n",
    "models.append(('LogReg',\n",
    "               LogisticRegression(C=3.73, random_state=0),'none'))\n",
    "\n",
    "# Logistic Regression (with standardized data)\n",
    "models.append(('LogReg(Std)',\n",
    "               LogisticRegression(C=3.73, random_state=0),'Std'))\n",
    "\n",
    "# Logistic Regression with standardized and important features\n",
    "models.append(('LogReg(Std&Imp)',\n",
    "               LogisticRegression(C=3.73, random_state=0),'imp'))\n",
    "\n",
    "# Decision Tree\n",
    "models.append(('Decision Tree', \n",
    "              DecisionTreeClassifier(criterion= 'entropy', max_depth= 4, \n",
    "                                     max_features= 7, min_samples_leaf= 8, \n",
    "                                     random_state=0),'none'))\n",
    "\n",
    "# Random Forest Classifier\n",
    "models.append(('Random Forest', \n",
    "              RandomForestClassifier(criterion= 'gini', max_depth= 6, \n",
    "                                     max_features= 5, n_estimators= 150, \n",
    "                                     random_state=0), 'none'))\n",
    "\n",
    "# Evaluate each model\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model, Std in models:\n",
    "    if Std == 'Std':\n",
    "        cv_results = cross_val_score(model, stdX, y, cv=5, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)       \n",
    "    elif Std == 'none':\n",
    "        cv_results = cross_val_score(model, X, y, cv=5, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "    else:\n",
    "        cv_results = cross_val_score(model, Ximp, y, cv=5, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "# Plot all the accuracy results vs. each model \n",
    "#(model type on the x-axis and accuracy on the y-axis).\n",
    "fig = pyplot.figure(figsize=(10,5))\n",
    "sns.set_context('notebook', font_scale=1.1)\n",
    "fig.suptitle('Algorithm Comparison - Accuracy (cv=5)')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results, showmeans=True)\n",
    "ax.set_xticklabels(names)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_ylim([0.75,1])\n",
    "plt.box(False)\n",
    "plt.savefig('ImageName', format='png', dpi=200, transparent=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy is obtained for the Random Forest Classifier with a mean accuracy of 0.82, yet it is the model with higher variation (0.0096). In general, all models have comparable mean accuracy. Nevertheless, because the classes are imbalanced (the proportion of non-default credit cards is higher than default) this metric is misleading. Furthermore, accuracy does not consider the rate of false positives (non-default credits cards that were predicted as default) and false negatives (default credit cards that were incorrectly predicted as non-default). Both cases have negative impact on the bank, since false positives leads to unsatisfied customers and false negatives leads to financial loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='m'></a>\n",
    "### Precision, Recall, F1-score\n",
    "The precision of a model is the ratio TP / (TP + FP). In this case, it is the ability of the classifier not to label as positive a sample that is negative. Precision is a good metric to use when the costs of false positive (FP) is high.\n",
    "\n",
    "The recall of a model is the ratio TP / (TP + FN). In this case, it is the ability of the classifier to find all the positive class. Recall is a good metric to use when the cost associated with false negative (FN) is high. In this classification problem there is a high cost for the bank when a default credit card is predicted as non-default, since no actions can be taken. Thus, recall is one important metric to pay attention to.\n",
    "\n",
    "F1-score is a weighted average of precision and recall. Thus, it considers FP and FN. This metric is very useful when we have uneven class distribution, as it seeks a balance between precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table, Column\n",
    "data_rows = [('Logistic Regression', 'Standardized', 0.79, 0.81, 0.77),\n",
    "              ('Logistic Regression', 'Important features', 0.79, 0.81, 0.78),\n",
    "              ('Decision Tree', 'original', 0.80, 0.82, 0.79),\n",
    "             ('Random Forest', 'original', 0.80, 0.82, 0.80)\n",
    "            ]\n",
    "t = Table(rows=data_rows, names=('Model', 'Data', 'Precision', 'Recall', 'F1'))\n",
    "print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
